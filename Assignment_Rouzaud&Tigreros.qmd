---
title: "StatisticalReasoning4"
author: "LuisRouzaud&AndresTigreros"
format: pdf
editor: visual
---

# 1. Practice with model comparison

------------------------------------------------------------------------

By making models, we are trying to approximate the processes that affect things in a system. It's important to know how well our models are actually aligning with reality though. If we are not careful, we may "overfit" our models. *Overfitting* is when our model fits the data too closely, usually because we added too many parameters, which explains the data well but makes the model very bad at predicting future data (for instance, the final panel of the XKCD comic below).

![XKCD_curve_fitting](photos/XKCD_curve_fitting.png){alt="XKCD_curve_fitting"}

It is common in the field of ecology to have multiple candidate models of how a system works. How do we know which is "best" at making predictions? In this activity we will learn two metrics that can help: the Watanabe–Akaike information criterion (**WAIC**) and Pareto Smoothed Importance Sampling (**PSIS**).

Both metrics tell us how well the model will predict data it wasn't trained on, which is important for thinking about how well the model might predict new data that we as scientists have not encountered yet.

------------------------------------------------------------------------

Let's start by reading in the relevant packages

```{r eval=FALSE}
library(brms) # for statistics 
library(tidyverse) # for data wrangling 
library(lterdatasampler)
```

We are going to work with the fiddler crab and latitude data again:

```{r}
pie_crab <- lterdatasampler::pie_crab
```

------------------------------------------------------------------------

In this section, we will run and interpret three multiple regressions to try and understand what influences crab body width in mm (`size`). These are data from crabs (\~30 per site) collected from sites from Florida to Massachusetts. Let's remind ourselves of the columns in the crab data:

```{r}
colnames(pie_crab)
```

We have multiple temperature variables that may be relevant to crab body size here, all measured in degrees Celsius. Mean annual air and water temperature data (`air_temp`, `water_temp`), plus the standard deviations of each (`air_temp_sd` and `water_temp_sd`, representing variability in temperature and perhaps seasonality).

------------------------------------------------------------------------

## 1.1 Create hypotheses for how each variable may affect crab size

Create four separate hypotheses describing how each predictor would be associated with larger or smaller crabs. Why? Please write 2-3 sentences for each predictor.

------------------------------------------------------------------------

### Q1.1a How might *mean* annual *water* temperature affect crab size?

H1: If the mean annual air temperature is higher, then the average crab will smaller. This because warmer air T° would cause and increase in the metabolic rates of crabs, causing them to mature faster and stop growing at smaller sizes

------------------------------------------------------------------------

### Q1.1b How might *mean* annual *air* temperature affect crab size?

H2: If the mean annual water temperature is higher, then the average crab will smaller. Hot water often leads to oxygen limitation in aquatic invertebrates; so since warmer water hold less oxygen, crabs will not support metabolic costs of a big body

------------------------------------------------------------------------

### Q1.1c How might the *sd* (variability) of *water* temperature affect crab size?

H3: If there is high variability (SD) in water temperature, then the average crab size will be smaller. Fluctuations in water temperature are physiologically stressful. This will force the crabs to loss energy away from growth and toward maintein their homeostasis.

------------------------------------------------------------------------

### Q1.1d How might the *sd* (variability) of *air* temperature affect crab size?

H4: If there is high variability (SD) in air temperature, then the average crab size will be larger. High variability often indicates strong seasonality; crabs in these ecosystems may evolve bigger bodies to store more energy in order to survive the periods of the year when temperatures are too extreme for getting food.

------------------------------------------------------------------------

## 1.2 Run, assess, and interpret three multiple regressions with latitude and *mean* temperatures

Let's run three regressions and compare their results. We will start by looking at how body size varies with latitude plus each of the mean temperature values separately, then together. Since these are intertidal estuarine sites, crabs are exposed to water for part of the day and air for another part; air and/or water temperatures may be important. The models will be:

-   size \~ latitude + water_temp
-   size \~ latitude + air_temp
-   size \~ latitude + water_temp + air_temp

------------------------------------------------------------------------

### size \~ latitude + mean water temp

```{r}
# latitude and water model
m.crab.lat.water <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + water_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.water")
```

Now look at the output:

```{r}
summary(m.crab.lat.water)
```

```{r}
plot(m.crab.lat.water)
```

#### Q1.2a Assess the output

Assess whether the model ran correctly by looking at R hat, the chains, and the posterior distributions using the plot() and summary() functions. Describe your thought process about whether the model ran correctly in 1-2 sentences.

**ANSWER:** The Rhat is 1, so is good. The chains look overlapping and flat, and the posterior distributions goes toward a central point.

------------------------------------------------------------------------

#### Q1.2b Interpret the output

Interpret your model by answering:

1.  What are the effects of your predictors? Remember to describe the effect using the units to make it biologically meaningful.
2.  Are the effects reasonably different from zero? How do you know?

**ANSWER:** latitude causes an effect of 0.8mm bigger by each degree we increase. This with, 95% ranges 0.58 to 1.04 not crossing the zero. Also, we increase 0.41mm of size per each degree celsius we increase with a 95% CI ranges 0.13 to 0.70, so they do not cross zero.

------------------------------------------------------------------------

### size \~ latitude + mean air temp

```{r}
# latitude and air model
m.crab.lat.air <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + air_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.air")
```

```{r}
summary(m.crab.lat.air)
plot(m.crab.lat.air)
```

#### Q1.3a Assess the output

Assess whether the model ran correctly by looking at R hat, the chains, and the posterior distributions using the plot() and summary() functions. Describe your thought process about whether the model ran correctly in 1-2 sentences.

**ANSWER:** The Rhat is 1 so is good. The chains look overlapping and flat, and the posterior distributions goes toward a central point.

------------------------------------------------------------------------

#### Q1.3b Interpret the output

Interpret your model by answering:

1.  What are the effects of your predictors? Remember to describe the effect using the units to make it biologically meaningful.
2.  Are the effects reasonably different from zero? How do you know?

**ANSWER:** We found that size decreases 0.99mm as we increase each degree of latitude. This has a 95% CI ranges from -1.66 to -0.33 not going through zero. Also, air temp decreases -1.67mm each degree of latitude we increase with a 95% CI going from -2.4 to -0.94. Not crossin zero :)

------------------------------------------------------------------------

### size \~ latitude + mean water + mean air temp

```{r}
# latitude and air model
m.crab.lat.air.water <- 
  brm(data = pie_crab, # Give the model the pie_crab data
      # Choose a gaussian (normal) distribution
      family = gaussian,
      # Specify the model here. 
      size ~ latitude + air_temp + water_temp,
      # Here's where you specify parameters for executing the Markov chains
      # We're using similar to the defaults, except we set cores to 4 so the analysis runs faster than the default of 1
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      # Setting the "seed" determines which random numbers will get sampled.
      # In this case, it makes the randomness of the Markov chain runs reproducible 
      # (so that both of us get the exact same results when running the model)
      seed = 4,
      # Save the fitted model object as output - helpful for reloading in the output later
      file = "temporary/m.crab.lat.air.water")
```

```{r}
summary(m.crab.lat.air.water)
plot(m.crab.lat.air.water)
```

#### Q1.4a Assess the output

Assess whether the model ran correctly by looking at R hat, the chains, and the posterior distributions using the plot() and summary() functions. Describe your thought process about whether the model ran correctly in 1-2 sentences.

**ANSWER:** The Rhat is 1 so is good. The chains look overlapping and flat, and the posterior distributions goes toward a central point.

------------------------------------------------------------------------

#### Q1.4b Interpret the output

Interpret your model by answering:

1.  What are the effects of your predictors? Remember to describe the effect using the units to make it biologically meaningful.
2.  Are the effects reasonably different from zero? How do you know?

**ANSWER:** latitude has a negative effect in size, decreasing 1.06mm by each degree we increase; CI95% ranges -1.70 to -0.43, so they do not cross zero. Air temperature also has a negative effect on size, decreasing 2.41mm per each celsius degree we increase; CI for this one goes from -3.18 to -1.65, so not crossing zero as well. Finally, for water temperature we have a positive effect, increasing the size of crabs 0.76mm pero each celsius degree we increase; 95% CI goes grom 0.47 to 1.05, not crossing zero as well

------------------------------------------------------------------------

#### Q1.5 How do the models differ in their estimates?

In 2-4 sentences, compare the three models' estimates of the effect of latitude, water temp, and air temp; did estimates change across different models? Stay the same? Change in whether or not they are different from zero?

**ANSWER:** Latitude had a positive effect on size when just looking at water temperature in the model. However, when we determined this using air temperature, it changed to a negative effect. When we include both of the terms, we found that both latitude and air temperature affect negatively the body size while water temperature has a positive effect.

#### Q1.5 Why do you think a variable's sign changed?

You should have noticed the change in sign for a variable. In 1-2 sentences, and in the context of your knowledge about causal inference from DAGs from last week, describe why you think the variable may have changed signs (hint: remember pipes?).

**ANSWER:** because probably latitude is correlated with both temperatures and there were an effect we were not accounting for. Including both variables on the analysis open this unknown variable and thats why we do have a different effect.

------------------------------------------------------------------------

## 1.3 Compare models using WAIC and PSIS

We just compared the models in terms of what values they provided for the estimates of the effects of `latitude`, `water_temp`, and `air_temp`. Now we are going to compare models using the Pareto Smoothed Importance Sampling (**PSIS**) and Watanabe–Akaike information criterion (**WAIC**). Remember, both of these metrics will tell us about a model's out of sample predictive skill. Lower values = better! A major reason we due this is to avoid *overfitting*, where more complex models with lots of parameters are un-generalizable to out of sample data.

First, let's look at the PSIS output from the three models. Remember, lower values are better, and more complicated models (models with more parameters) will be "punished", since more parameters risks overfitting.

```{r}
# Look at "leave one out" results for all three models
# size ~ lat + mean water
loo(m.crab.lat.water)
# size ~ lat + mean air
loo(m.crab.lat.air)
# size ~ lat + mean water + mean air
loo(m.crab.lat.air.water)
```

The first thing to look for to assess the leave one out method is the Pareto k estimate. For us, it gives the helpful message: `All Pareto k estimates are good (k < 0.7)`.

The last row in each table's output is our PSIS value. Remember, lower = better. As we can see, the `size ~ latitude + mean water + mean air` model had the lowers PSIS value, despite having the most parameters. This indicates that the extra parameter made up for the punishment by adding much more predictive power.

------------------------------------------------------------------------

Now we do the same for WAIC:

```{r}
# Look at "leave one out" results for all three models
# size ~ lat + mean water
waic(m.crab.lat.water)
# size ~ lat + mean air
waic(m.crab.lat.air)
# size ~ lat + mean water + mean air
waic(m.crab.lat.air.water)
```

### Q1.7 Which model has the "best" WAIC value?

Remember, lower is better!

**ANSWER:** the model with lower WAIC = 1890.6 is the crab size \~ lat + mean water temp + mean air temperature

Importantly, we want both the PSIS results and the WAIC results to align. In this case, they do, which is a good sign for our models.

## 1.4 Look at uncertainty around model predictions

Here we will look at some of the ways we can look at the uncertainty around model predictions form the "model evaluation" lecture using the most complex model with `size ~ latitude + mean water + mean air`.

The `predict_response(interval = "prediction")` function plots the 95% prediction intervals separately for each predictor, displaying uncertainty around where the data may lay around the model.

```{r}
preds <- ggeffects::predict_response(m.crab.lat.air.water,                              interval = "prediction") 
plot(preds)
```

There are a few posterior predictive check plots we can look at. For instance, `pp_check(type = "dens_overlay")` shows the probability density of the observed data in a heavy line. The thin blue lines show the range of probability densities that are expected if you simulate from the fitted model's range of estimated posteriors. We want the thin blue lines to align pretty well with the heavy line.

```{r}
pp_check(m.crab.lat.air.water, type = "dens_overlay")
```

`pp_check(type = "scatter_avg")` shows the observed values on the y axis and the average of the predicted values on the x axis using a scatterplot. Having all of the points fall along the 1:1 line would indicate good fit. Points that fall outside that line can help us understand whether there are missing predictors.

```{r}
pp_check(m.crab.lat.air.water, type = "scatter_avg")
```

Here, it seems that there is a lot of variation at each site: remember, each site (which has one value of latitude) has \~30 crabs. The model line goes through approximately the middle of each cloud of points, which is good, but there is still a lot of unexplained variation at seemingly the site level. This may mean that there are site-specific variables that are causing variation in crab size that are not captured in this model.

------------------------------------------------------------------------

## 2. Repeat with the sd of water and air temp instead of mean temp

------------------------------------------------------------------------

Now it's your turn! In this section, repeat what we just did but with the standard deviation (sd) of water and air temperature instead of the mean air and water temperature.

The three models should be:

-   size \~ latitude + water_temp_sd
-   size \~ latitude + air_temp_sd
-   size \~ latitude + water_temp_sd + air_temp_sd

### Q2.1 Run all three models

Run and store all three models. Remember to change the name of 1) the data that the model output is stored as and 2) the output file name

**ANSWER:**

#### size \~ latitude + water temp sd

```{r}
m.crab.lat.water_sd <- 
  brm(data = pie_crab,
      family = gaussian,
      size ~ latitude + water_temp_sd,
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4,
      file = "temporary/m.crab.lat.water_sd")
```

```{r}
summary(m.crab.lat.water_sd)
```

```{r}
plot(m.crab.lat.water_sd)
```

#### size \~ latitude + air temp sd

```{r}
m.crab.lat.air_sd <- 
  brm(data = pie_crab,
      family = gaussian,
      size ~ latitude + air_temp_sd,
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4,
      file = "temporary/m.crab.lat.air_sd")
```

```{r}
summary(m.crab.lat.air_sd)
```

```{r}
plot(m.crab.lat.air_sd)
```

#### size \~ latitude + water temp sd + air temp sd

```{r}
m.crab.lat.water.air_sd <- 
  brm(data = pie_crab,
      family = gaussian,
      size ~ latitude + water_temp_sd + air_temp_sd,
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4,
      file = "temporary/m.crab.lat.water.air_sd")
```

```{r}
summary(m.crab.lat.water.air_sd)
```

```{r}
plot(m.crab.lat.water.air_sd)
```

### Q2.2 Assess all three models

Assess whether each model ran correctly by looking at R hat, the chains, and the posterior distributions using the plot() and summary() functions. Describe your thought process about whether the model ran correctly in 1-2 sentences per model.

**ANSWER:** For all three models ran we observe that the RHAT is good in each with a value of 1.00. Also, chains look flat and good and the posterior distributions seem decent

------------------------------------------------------------------------

### Q2.3 Interpret all three models

Interpret all three models by answering:

1.  What are the effects of your predictors? Remember to describe the effect using the units to make it biologically meaningful.
2.  Are the effects reasonably different from zero? How do you know?

Please write 2-3 sentences for each model

**ANSWER:**

```{r}
summary(m.crab.lat.water_sd) #(1)
summary(m.crab.lat.air_sd) #(2)
summary(m.crab.lat.water.air_sd) #(3)
```

For 1) we found that there is a positive effect of latitude on crab size with 0.48mm of increase per each sd we go up. This parameter has CI 95% going from 0.03 to 0.42, not crossing zero. Also, water temperature sd has a positive effect of increase 0.02mm size as we go up each celsius degree of standard deviation. However, this one seems not confident because the CI goes crom -0.22 to 0.26 through zero.

For 2) we found that there is also a positive effect of latitude, increasi 0.53mm of size each latitude degree we increase, being confident of this result because CI 95% goes from 0.42 to 0.64, not crossing zero. However, air temperate sd seems to have a negative effect, decreasing 0.24mm size as we increase 1 celsius degree of standard deviation. However, this do not seem confident due to cross zero, CI goes from -0.71 to 0.26

For 3), which includes both, we have a different interpretation. In this model , latitude and water temperature sd both increase size. This by 0.56 and 0.15 mm respectively as we increase each respective degree of latitude and celsius temperature. Latitude is trustworthy because it do not cross zero on its CI, goes from 0.43 to 0.68, while water temp sd goes from -0.18 to 0.47 is not a good result. On the other hand, air temp sd has a negative effect on crab size. It decreases their size by 0.4 mm as we increase in celisus of standard deviation

------------------------------------------------------------------------

### Q2.4 How do the models differ in their parameter estimates?

In 2-4 sentences, compare the three models' estimates of the effect of latitude, water temp sd, and air temp sd; did estimates change across different models? Stay the same? Change in whether or not they are different from zero?

**ANSWER:** Latitude changed in a slight way its effect across the models that were run. All its CI 95% never crossed zero. However, air and water temperature sd's varied in their estimates and always included or crossed the zero in their CI. So, these variables have no effect

------------------------------------------------------------------------

### Q2.5 Calculate and compare PSIS and AIC values for each model

Calculate and compare the PSIS and AIC values for each model and answer:

1.  Are the Pareto k estimates good?
2.  Which model has the lowest PSIS?
3.  Which model has the lowest AIC?
4.  Do PSIS and AIC values agree on which model has the best out of sample prediction?

**ANSWER:**

```{r}
loo(m.crab.lat.water_sd)
loo(m.crab.lat.air_sd)
loo(m.crab.lat.water.air_sd)
```

```{r}
waic(m.crab.lat.water_sd)
waic(m.crab.lat.air_sd)
waic(m.crab.lat.water.air_sd)
```

**ANSWER:**

1.  The Paretos are nice because all of them are below 0.7

2.  Model with lowest PSIS is the model size \~ latitude + air temp sd

3.  Model with lowest WAIC is the model size \~ latitude + air temp sd

4.  Yes, both the PSIS and WAIC agreed on which is the best output which is the second model. However, is it right? They do have both the SAME results. Calvin mentioned that this may happen when you have enough sample size so the math of both PSIS and WAIC converge.
